{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea for tuning:\n",
    "\n",
    "need to specify which metrics need to be computed, which one needs to be minimized, and how large k is\n",
    "\n",
    "* build k splits into train and test data\n",
    "* for each train-test-split:\n",
    "    * build a parameter grid using cls.tuning_params. (For each class we have to find out what a good grid would be.)\n",
    "    * for each combination in the grid: \n",
    "        * translate api-response into f,m,u and store in the column gender_infered \n",
    "        * compute all provided metrics on the resulting test_data DF restricted to training data\n",
    "        * store relation grid-point:metrics\n",
    "    * select grid_point which minimizes specified metric and compute all provided metrics on test set\n",
    "    * store the metrics on test set\n",
    "* compute average of metrics on all test sets for all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluators import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `genderize_io`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'all'\n",
    "service_name = GenderizeIoEvaluator\n",
    "evaluator = service_name(data_source)\n",
    "\n",
    "evaluator.load_data(evaluated=True)\n",
    "evaluator.preprocess_data_for_parameter_tuning()\n",
    "evaluator.remove_rows_with_unknown_gender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>origin</th>\n",
       "      <th>api_count</th>\n",
       "      <th>api_gender</th>\n",
       "      <th>api_name</th>\n",
       "      <th>api_probability</th>\n",
       "      <th>gender_infered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>pierre</td>\n",
       "      <td>paul</td>\n",
       "      <td>grivel</td>\n",
       "      <td>pierre paul grivel</td>\n",
       "      <td>m</td>\n",
       "      <td>zbmath</td>\n",
       "      <td>5.0</td>\n",
       "      <td>male</td>\n",
       "      <td>pierre-paul</td>\n",
       "      <td>1.00</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>raul</td>\n",
       "      <td></td>\n",
       "      <td>serapioni</td>\n",
       "      <td>raul serapioni</td>\n",
       "      <td>m</td>\n",
       "      <td>zbmath</td>\n",
       "      <td>821.0</td>\n",
       "      <td>male</td>\n",
       "      <td>raul</td>\n",
       "      <td>1.00</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>adriano</td>\n",
       "      <td></td>\n",
       "      <td>moura</td>\n",
       "      <td>adriano moura</td>\n",
       "      <td>m</td>\n",
       "      <td>zbmath</td>\n",
       "      <td>166.0</td>\n",
       "      <td>male</td>\n",
       "      <td>adriano</td>\n",
       "      <td>0.99</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ralf</td>\n",
       "      <td></td>\n",
       "      <td>kieser</td>\n",
       "      <td>ralf kieser</td>\n",
       "      <td>m</td>\n",
       "      <td>zbmath</td>\n",
       "      <td>86.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ralf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>guillermo</td>\n",
       "      <td></td>\n",
       "      <td>leon-de-la-barra</td>\n",
       "      <td>guillermo leon-de-la-barra</td>\n",
       "      <td>m</td>\n",
       "      <td>zbmath</td>\n",
       "      <td>850.0</td>\n",
       "      <td>male</td>\n",
       "      <td>guillermo</td>\n",
       "      <td>1.00</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index first_name middle_name         last_name                   full_name  \\\n",
       "0      0     pierre        paul            grivel          pierre paul grivel   \n",
       "1      1       raul                     serapioni              raul serapioni   \n",
       "2      2    adriano                         moura               adriano moura   \n",
       "3      3       ralf                        kieser                 ralf kieser   \n",
       "4      5  guillermo              leon-de-la-barra  guillermo leon-de-la-barra   \n",
       "\n",
       "  gender  origin  api_count api_gender     api_name  api_probability  \\\n",
       "0      m  zbmath        5.0       male  pierre-paul             1.00   \n",
       "1      m  zbmath      821.0       male         raul             1.00   \n",
       "2      m  zbmath      166.0       male      adriano             0.99   \n",
       "3      m  zbmath       86.0       male         ralf             1.00   \n",
       "4      m  zbmath      850.0       male    guillermo             1.00   \n",
       "\n",
       "  gender_infered  \n",
       "0              m  \n",
       "1              m  \n",
       "2              m  \n",
       "3              m  \n",
       "4              m  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api_count</th>\n",
       "      <th>api_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5227.000000</td>\n",
       "      <td>5227.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1695.015496</td>\n",
       "      <td>0.957744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2638.971903</td>\n",
       "      <td>0.105776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>503.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2201.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12593.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          api_count  api_probability\n",
       "count   5227.000000      5227.000000\n",
       "mean    1695.015496         0.957744\n",
       "std     2638.971903         0.105776\n",
       "min        1.000000         0.500000\n",
       "25%       46.000000         0.990000\n",
       "50%      503.000000         1.000000\n",
       "75%     2201.000000         1.000000\n",
       "max    12593.000000         1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.test_data[list(evaluator.tuning_params)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_pred</th>\n",
       "      <th>m_pred</th>\n",
       "      <th>u_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>1722</td>\n",
       "      <td>88</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>220</td>\n",
       "      <td>3197</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_pred  m_pred  u_pred\n",
       "f    1722      88     151\n",
       "m     220    3197     412\n",
       "u       0       0       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show confusion matrix if we do no tuning\n",
    "evaluator._translate_api_response()\n",
    "evaluator.compute_confusion_matrix(evaluator.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('api_count', 100), ('api_probability', 0.8)]),\n",
       " OrderedDict([('api_count', 100), ('api_probability', 0.85)]),\n",
       " OrderedDict([('api_count', 100), ('api_probability', 0.9)]),\n",
       " OrderedDict([('api_count', 500), ('api_probability', 0.8)]),\n",
       " OrderedDict([('api_count', 500), ('api_probability', 0.85)]),\n",
       " OrderedDict([('api_count', 500), ('api_probability', 0.9)]),\n",
       " OrderedDict([('api_count', 1000), ('api_probability', 0.8)]),\n",
       " OrderedDict([('api_count', 1000), ('api_probability', 0.85)]),\n",
       " OrderedDict([('api_count', 1000), ('api_probability', 0.9)])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only for testing\n",
    "evaluator.build_parameter_grid([100, 500, 1000], [0.8, 0.85, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a sample grid\n",
    "grid = evaluator.build_parameter_grid([1, 10, 100, 200, 300], \n",
    "                                      [0.5, 0.7, 0.8, 0.9, 0.95, 0.97, 0.98, 0.98, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 0.5): 0.058924813468528792,\n",
       " (1, 0.7): 0.037021969080553295,\n",
       " (1, 0.8): 0.031067556296914094,\n",
       " (1, 0.9): 0.024731888815933464,\n",
       " (1, 0.95): 0.020702070207020702,\n",
       " (1, 0.97): 0.019462465245597776,\n",
       " (1, 0.98): 0.019458946369245372,\n",
       " (1, 1): 0.021270221689634512,\n",
       " (10, 0.5): 0.052019315188762072,\n",
       " (10, 0.7): 0.030303030303030304,\n",
       " (10, 0.8): 0.023661567877629065,\n",
       " (10, 0.9): 0.017306245297215951,\n",
       " (10, 0.95): 0.012428793371310202,\n",
       " (10, 0.97): 0.010712372790573112,\n",
       " (10, 0.98): 0.010462555066079295,\n",
       " (10, 1): 0.0097968069666182871,\n",
       " (100, 0.5): 0.035132819194515851,\n",
       " (100, 0.7): 0.01854066985645933,\n",
       " (100, 0.8): 0.014625228519195612,\n",
       " (100, 0.9): 0.0097545626179987421,\n",
       " (100, 0.95): 0.0064370775667846793,\n",
       " (100, 0.97): 0.0065984823490597162,\n",
       " (100, 0.98): 0.0064232589587559161,\n",
       " (100, 1): 0.0051139005113900512,\n",
       " (200, 0.5): 0.031496062992125984,\n",
       " (200, 0.7): 0.015491100856954515,\n",
       " (200, 0.8): 0.013368983957219251,\n",
       " (200, 0.9): 0.0089500860585197926,\n",
       " (200, 0.95): 0.0059711977520196698,\n",
       " (200, 0.97): 0.0061195104391648667,\n",
       " (200, 0.98): 0.005884516366311144,\n",
       " (200, 1): 0.0049480455220188022,\n",
       " (300, 0.5): 0.027654489586889725,\n",
       " (300, 0.7): 0.013869132290184922,\n",
       " (300, 0.8): 0.011552346570397111,\n",
       " (300, 0.9): 0.0074183976261127599,\n",
       " (300, 0.95): 0.0045437334343051876,\n",
       " (300, 0.97): 0.0046457607433217189,\n",
       " (300, 0.98): 0.0043461082576056898,\n",
       " (300, 1): 0.003186404673393521}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: turn errors into a nice dataframe for the paper \n",
    "index = evaluator.test_data.index\n",
    "errors = evaluator.compute_error_for_param_grid(grid, evaluator.compute_error_without_unknown, index)\n",
    "errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 0.150723385878 corresponding test error: 0.149266609146\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.5}\n",
      "minimal train error: 0.153281519862 corresponding test error: 0.139032815199\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.5}\n",
      "minimal train error: 0.148100172712 corresponding test error: 0.1597582038\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.5}\n",
      "minimal train error: 0.150690846287 corresponding test error: 0.149395509499\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.5}\n",
      "minimal train error: 0.149363263544 corresponding test error: 0.154710458081\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15043271914489384"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(5, grid, evaluator.compute_error_with_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 0.00334448160535 corresponding test error: 0.00257731958763\n",
      "params for lowest train error: {'api_count': 300, 'api_probability': 1}\n",
      "minimal train error: 0.00333333333333 corresponding test error: 0.00261096605744\n",
      "params for lowest train error: {'api_count': 300, 'api_probability': 1}\n",
      "minimal train error: 0.00394736842105 corresponding test error: 0.0\n",
      "params for lowest train error: {'api_count': 300, 'api_probability': 1}\n",
      "minimal train error: 0.00331125827815 corresponding test error: 0.00268096514745\n",
      "params for lowest train error: {'api_count': 300, 'api_probability': 1}\n",
      "minimal train error: 0.00199071001991 corresponding test error: 0.00797872340426\n",
      "params for lowest train error: {'api_count': 300, 'api_probability': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0031695948393557043"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(5, grid, evaluator.compute_error_without_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 0.0995465342259 corresponding test error: 0.0880069025022\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.5}\n",
      "minimal train error: 0.0984455958549 corresponding test error: 0.0924006908463\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.5}\n",
      "minimal train error: 0.0949913644214 corresponding test error: 0.10621761658\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.5}\n",
      "minimal train error: 0.0971502590674 corresponding test error: 0.0975820379965\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.5}\n",
      "minimal train error: 0.096050075545 corresponding test error: 0.101987899741\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.097239029533201821"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(5, grid, evaluator.compute_error_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out a weighted version of `compute_error_with_unknown`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 0.0850524791893 corresponding test error: 0.0887104575796\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.7}\n",
      "minimal train error: 0.0872564443907 corresponding test error: 0.0799656061909\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.7}\n",
      "minimal train error: 0.0845121334072 corresponding test error: 0.0909090909091\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.7}\n",
      "minimal train error: 0.0863446544524 corresponding test error: 0.0835345243844\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.7}\n",
      "minimal train error: 0.0857542708233 corresponding test error: 0.0858966918166\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.7}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08580327417609987"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(5, grid, evaluator.compute_weighted_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_pred</th>\n",
       "      <th>m_pred</th>\n",
       "      <th>u_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>1671</td>\n",
       "      <td>52</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>130</td>\n",
       "      <td>3063</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_pred  m_pred  u_pred\n",
       "f    1671      52     238\n",
       "m     130    3063     636\n",
       "u       0       0       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show confusion matrix if we tune parameters according to error function 'compute_weighted_error'\n",
    "evaluator._translate_api_response(api_count=1, api_probability=0.7)\n",
    "evaluator.compute_confusion_matrix(evaluator.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try setting a constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parameter values satisfied given constraint\n",
      "No parameter values satisfied given constraint\n"
     ]
    }
   ],
   "source": [
    "# we tune parameters such that 'error_func' is minimised on the training sets \n",
    "# but under the constraint that 'constraint_func' is less than 'constraint_val' on test set\n",
    "evaluator.compute_cv_score(n_splits=5, param_grid=grid, error_func=evaluator.compute_error_without_unknown,\n",
    "                          constraint_func=evaluator.compute_error_with_unknown, constraint_val=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 0.00675675675676 corresponding test error: 0.00508474576271\n",
      "params for lowest train error: {'api_count': 100, 'api_probability': 0.98}\n",
      "minimal train error: 0.0061919504644 corresponding test error: 0.00511945392491\n",
      "params for lowest train error: {'api_count': 200, 'api_probability': 0.95}\n",
      "minimal train error: 0.00678913738019 corresponding test error: 0.00497512437811\n",
      "params for lowest train error: {'api_count': 100, 'api_probability': 0.95}\n",
      "minimal train error: 0.00590468156896 corresponding test error: 0.00851788756388\n",
      "params for lowest train error: {'api_count': 100, 'api_probability': 0.98}\n",
      "minimal train error: 0.00549915397631 corresponding test error: 0.010101010101\n",
      "params for lowest train error: {'api_count': 100, 'api_probability': 0.98}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.006759644346126051"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(n_splits=5, param_grid=grid, error_func=evaluator.compute_error_without_unknown,\n",
    "                          constraint_func=evaluator.compute_error_with_unknown, constraint_val=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 0.0199494239955 corresponding test error: 0.0237288135593\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.95}\n",
      "minimal train error: 0.0195278344506 corresponding test error: 0.019209039548\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.97}\n",
      "minimal train error: 0.0212587412587 corresponding test error: 0.0184119677791\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.95}\n",
      "minimal train error: 0.019437191761 corresponding test error: 0.0195627157652\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.97}\n",
      "minimal train error: 0.0205056179775 corresponding test error: 0.0214932126697\n",
      "params for lowest train error: {'api_count': 1, 'api_probability': 0.95}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02048114986426634"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(n_splits=5, param_grid=grid, error_func=evaluator.compute_error_without_unknown,\n",
    "                          constraint_func=evaluator.compute_error_unknown, constraint_val=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `gender_api`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'all'\n",
    "service_name = GenderAPIEvaluator\n",
    "evaluator = service_name(data_source)\n",
    "\n",
    "evaluator.load_data(evaluated=True)\n",
    "evaluator.preprocess_data_for_parameter_tuning()\n",
    "evaluator.remove_rows_with_unknown_gender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('api_accuracy', 'api_samples')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.tuning_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api_accuracy</th>\n",
       "      <th>api_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5790.000000</td>\n",
       "      <td>5790.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>91.385320</td>\n",
       "      <td>40243.978066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.721861</td>\n",
       "      <td>66650.027682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>987.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>11153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>51412.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>433182.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       api_accuracy    api_samples\n",
       "count   5790.000000    5790.000000\n",
       "mean      91.385320   40243.978066\n",
       "std       18.721861   66650.027682\n",
       "min        0.000000       0.000000\n",
       "25%       95.000000     987.000000\n",
       "50%       98.000000   11153.000000\n",
       "75%       99.000000   51412.000000\n",
       "max      100.000000  433182.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.test_data[list(evaluator.tuning_params)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_pred</th>\n",
       "      <th>m_pred</th>\n",
       "      <th>u_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>1728</td>\n",
       "      <td>187</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>141</td>\n",
       "      <td>3560</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_pred  m_pred  u_pred\n",
       "f    1728     187      46\n",
       "m     141    3560     128\n",
       "u       0       0       0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show confusion matrix if we do no tuning\n",
    "evaluator._translate_api_response()\n",
    "evaluator.compute_confusion_matrix(evaluator.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = evaluator.build_parameter_grid([50, 60, 70, 80, 90, 95], [10000, 20000, 30000, 40000, 50000, 60000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 0.00460405156538 corresponding test error: 0.00684931506849\n",
      "params for lowest train error: {'api_samples': 50000, 'api_accuracy': 95}\n",
      "minimal train error: 0.00522951772225 corresponding test error: 0.00660792951542\n",
      "params for lowest train error: {'api_samples': 20000, 'api_accuracy': 95}\n",
      "minimal train error: 0.00542005420054 corresponding test error: 0.00369003690037\n",
      "params for lowest train error: {'api_samples': 50000, 'api_accuracy': 95}\n",
      "minimal train error: 0.00441014332966 corresponding test error: 0.010152284264\n",
      "params for lowest train error: {'api_samples': 60000, 'api_accuracy': 95}\n",
      "minimal train error: 0.00546946216955 corresponding test error: 0.00355871886121\n",
      "params for lowest train error: {'api_samples': 50000, 'api_accuracy': 95}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0061716569218900012"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(5, grid, evaluator.compute_error_without_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 1.00476190476 corresponding test error: 0.944630872483\n",
      "params for lowest train error: {'api_samples': 10000, 'api_accuracy': 50}\n",
      "minimal train error: 1.00954446855 corresponding test error: 0.926788685524\n",
      "params for lowest train error: {'api_samples': 10000, 'api_accuracy': 50}\n",
      "minimal train error: 0.96855078623 corresponding test error: 1.09403254973\n",
      "params for lowest train error: {'api_samples': 10000, 'api_accuracy': 50}\n",
      "minimal train error: 0.981180496151 corresponding test error: 1.03873239437\n",
      "params for lowest train error: {'api_samples': 10000, 'api_accuracy': 50}\n",
      "minimal train error: 0.998705780846 corresponding test error: 0.96768707483\n",
      "params for lowest train error: {'api_samples': 10000, 'api_accuracy': 50}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99437431538644583"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(5, grid, evaluator.compute_error_with_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 1.00889328063 corresponding test error: 1.01119402985\n",
      "params for lowest train error: {'api_samples': 20000, 'api_accuracy': 95}\n",
      "minimal train error: 1.00872093023 corresponding test error: 1.01209677419\n",
      "params for lowest train error: {'api_samples': 20000, 'api_accuracy': 95}\n",
      "minimal train error: 1.01046337818 corresponding test error: 1.00943396226\n",
      "params for lowest train error: {'api_samples': 10000, 'api_accuracy': 95}\n",
      "minimal train error: 1.00863723608 corresponding test error: 1.01260504202\n",
      "params for lowest train error: {'api_samples': 20000, 'api_accuracy': 95}\n",
      "minimal train error: 1.0099009901 corresponding test error: 1.00740740741\n",
      "params for lowest train error: {'api_samples': 20000, 'api_accuracy': 95}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.010547443146532"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(5, grid, evaluator.compute_inverse_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
