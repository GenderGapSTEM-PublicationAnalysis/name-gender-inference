{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea for tuning:\n",
    "\n",
    "need to specify which metrics need to be computed, which one needs to be minimized, and how large k is\n",
    "\n",
    "* build k splits into train and test data\n",
    "* for each train-test-split:\n",
    "    * build a parameter grid using cls.tuning_params. (For each class we have to find out what a good grid would be.)\n",
    "    * for each combination in the grid: \n",
    "        * translate api-response into f,m,u and store in the column gender_infered \n",
    "        * compute all provided metrics on the resulting test_data DF restricted to training data\n",
    "        * store relation grid-point:metrics\n",
    "    * select grid_point which minimizes specified metric and compute all provided metrics on test set\n",
    "    * store the metrics on test set\n",
    "* compute average of metrics on all test sets for all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluators import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `genderize_io`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'genderizeR'\n",
    "service_name = GenderizeIoEvaluator\n",
    "evaluator = service_name(data_source)\n",
    "\n",
    "evaluator.load_data(evaluated=True)\n",
    "evaluator.preprocess_data_for_parameter_tuning()\n",
    "evaluator.remove_rows_with_unknown_gender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>raw_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>api_count</th>\n",
       "      <th>gender_infered</th>\n",
       "      <th>api_name</th>\n",
       "      <th>api_probability</th>\n",
       "      <th>api_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chiesa, Paolo</td>\n",
       "      <td>paolo</td>\n",
       "      <td></td>\n",
       "      <td>chiesa</td>\n",
       "      <td>paolo chiesa</td>\n",
       "      <td>m</td>\n",
       "      <td>781.0</td>\n",
       "      <td>m</td>\n",
       "      <td>paolo</td>\n",
       "      <td>0.99</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Abbate, Ernesto</td>\n",
       "      <td>ernesto</td>\n",
       "      <td></td>\n",
       "      <td>abbate</td>\n",
       "      <td>ernesto abbate</td>\n",
       "      <td>m</td>\n",
       "      <td>381.0</td>\n",
       "      <td>m</td>\n",
       "      <td>ernesto</td>\n",
       "      <td>1.00</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Epstein, John H.</td>\n",
       "      <td>john</td>\n",
       "      <td></td>\n",
       "      <td>epstein</td>\n",
       "      <td>john epstein</td>\n",
       "      <td>m</td>\n",
       "      <td>9931.0</td>\n",
       "      <td>m</td>\n",
       "      <td>john</td>\n",
       "      <td>0.99</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cotroneo, Margaret</td>\n",
       "      <td>margaret</td>\n",
       "      <td></td>\n",
       "      <td>cotroneo</td>\n",
       "      <td>margaret cotroneo</td>\n",
       "      <td>f</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>f</td>\n",
       "      <td>margaret</td>\n",
       "      <td>0.98</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Kresge, Nicole</td>\n",
       "      <td>nicole</td>\n",
       "      <td></td>\n",
       "      <td>kresge</td>\n",
       "      <td>nicole kresge</td>\n",
       "      <td>f</td>\n",
       "      <td>4042.0</td>\n",
       "      <td>f</td>\n",
       "      <td>nicole</td>\n",
       "      <td>1.00</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            raw_name first_name middle_name last_name  \\\n",
       "0      1       Chiesa, Paolo      paolo                chiesa   \n",
       "1      2     Abbate, Ernesto    ernesto                abbate   \n",
       "2      3    Epstein, John H.       john               epstein   \n",
       "3      4  Cotroneo, Margaret   margaret              cotroneo   \n",
       "4      5      Kresge, Nicole     nicole                kresge   \n",
       "\n",
       "           full_name gender  api_count gender_infered  api_name  \\\n",
       "0       paolo chiesa      m      781.0              m     paolo   \n",
       "1     ernesto abbate      m      381.0              m   ernesto   \n",
       "2       john epstein      m     9931.0              m      john   \n",
       "3  margaret cotroneo      f     1101.0              f  margaret   \n",
       "4      nicole kresge      f     4042.0              f    nicole   \n",
       "\n",
       "   api_probability api_gender  \n",
       "0             0.99       male  \n",
       "1             1.00       male  \n",
       "2             0.99       male  \n",
       "3             0.98     female  \n",
       "4             1.00     female  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api_count</th>\n",
       "      <th>api_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>397.000000</td>\n",
       "      <td>397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2456.032746</td>\n",
       "      <td>0.978262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3288.578471</td>\n",
       "      <td>0.069072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>145.000000</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>972.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3568.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12593.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          api_count  api_probability\n",
       "count    397.000000       397.000000\n",
       "mean    2456.032746         0.978262\n",
       "std     3288.578471         0.069072\n",
       "min        1.000000         0.520000\n",
       "25%      145.000000         0.990000\n",
       "50%      972.000000         1.000000\n",
       "75%     3568.000000         1.000000\n",
       "max    12593.000000         1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.test_data[list(evaluator.tuning_params)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_pred</th>\n",
       "      <th>m_pred</th>\n",
       "      <th>u_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>8</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_pred  m_pred  u_pred\n",
       "f      83       2       0\n",
       "m       8     304       0\n",
       "u       0       0       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show confusion matrix if we do no tuning\n",
    "evaluator._translate_api_response()\n",
    "evaluator.compute_confusion_matrix(evaluator.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('api_count', 100), ('api_probability', 0.8)]),\n",
       " OrderedDict([('api_count', 100), ('api_probability', 0.85)]),\n",
       " OrderedDict([('api_count', 100), ('api_probability', 0.9)]),\n",
       " OrderedDict([('api_count', 500), ('api_probability', 0.8)]),\n",
       " OrderedDict([('api_count', 500), ('api_probability', 0.85)]),\n",
       " OrderedDict([('api_count', 500), ('api_probability', 0.9)]),\n",
       " OrderedDict([('api_count', 1000), ('api_probability', 0.8)]),\n",
       " OrderedDict([('api_count', 1000), ('api_probability', 0.85)]),\n",
       " OrderedDict([('api_count', 1000), ('api_probability', 0.9)])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only for testing\n",
    "evaluator.build_parameter_grid([100, 500, 1000], [0.8, 0.85, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a sample grid\n",
    "grid = evaluator.build_parameter_grid([1, 10, 100, 200, 300], \n",
    "                                      [0.5, 0.7, 0.8, 0.9, 0.95, 0.97, 0.98, 0.98, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 0.5): 0.025188916876574308,\n",
       " (1, 0.7): 0.017994858611825194,\n",
       " (1, 0.8): 0.013192612137203167,\n",
       " (1, 0.9): 0.01078167115902965,\n",
       " (1, 0.95): 0.010899182561307902,\n",
       " (1, 0.97): 0.0111731843575419,\n",
       " (1, 0.98): 0.011235955056179775,\n",
       " (1, 1): 0.015384615384615385,\n",
       " (10, 0.5): 0.018617021276595744,\n",
       " (10, 0.7): 0.010840108401084011,\n",
       " (10, 0.8): 0.0055710306406685237,\n",
       " (10, 0.9): 0.002840909090909091,\n",
       " (10, 0.95): 0.0028735632183908046,\n",
       " (10, 0.97): 0.0029498525073746312,\n",
       " (10, 0.98): 0.002967359050445104,\n",
       " (10, 1): 0.0041493775933609959,\n",
       " (100, 0.5): 0.0065573770491803279,\n",
       " (100, 0.7): 0.0033333333333333335,\n",
       " (100, 0.8): 0.0,\n",
       " (100, 0.9): 0.0,\n",
       " (100, 0.95): 0.0,\n",
       " (100, 0.97): 0.0,\n",
       " (100, 0.98): 0.0,\n",
       " (100, 1): 0.0,\n",
       " (200, 0.5): 0.006993006993006993,\n",
       " (200, 0.7): 0.0035587188612099642,\n",
       " (200, 0.8): 0.0,\n",
       " (200, 0.9): 0.0,\n",
       " (200, 0.95): 0.0,\n",
       " (200, 0.97): 0.0,\n",
       " (200, 0.98): 0.0,\n",
       " (200, 1): 0.0,\n",
       " (300, 0.5): 0.0076045627376425855,\n",
       " (300, 0.7): 0.0038610038610038611,\n",
       " (300, 0.8): 0.0,\n",
       " (300, 0.9): 0.0,\n",
       " (300, 0.95): 0.0,\n",
       " (300, 0.97): 0.0,\n",
       " (300, 0.98): 0.0,\n",
       " (300, 1): 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: turn errors into a nice dataframe for the paper \n",
    "index = evaluator.test_data.index\n",
    "errors = evaluator.compute_error_for_param_grid(grid, evaluator.compute_error_without_unknown, index)\n",
    "errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out a weighted version of `compute_error_with_unknown`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 0.0162774239207 corresponding test error: 0.0121786197564\n",
      "params for lowest train error: {'api_probability': 0.9, 'api_count': 10}\n",
      "minimal train error: 0.016106442577 corresponding test error: 0.0126939351199\n",
      "params for lowest train error: {'api_probability': 0.9, 'api_count': 10}\n",
      "minimal train error: 0.0104529616725 corresponding test error: 0.0369393139842\n",
      "params for lowest train error: {'api_probability': 0.8, 'api_count': 10}\n",
      "minimal train error: 0.017199017199 corresponding test error: 0.00837988826816\n",
      "params for lowest train error: {'api_probability': 0.9, 'api_count': 10}\n",
      "minimal train error: 0.015939015939 corresponding test error: 0.0132547864507\n",
      "params for lowest train error: {'api_probability': 0.9, 'api_count': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016689308715860558"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(5, grid, evaluator.compute_weighted_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_pred</th>\n",
       "      <th>m_pred</th>\n",
       "      <th>u_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>1</td>\n",
       "      <td>274</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_pred  m_pred  u_pred\n",
       "f      77       0       8\n",
       "m       1     274      37\n",
       "u       0       0       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show confusion matrix if we tune parameters according to error function 'compute_weighted_error'\n",
    "evaluator._translate_api_response(api_count=10, api_probability=0.9)\n",
    "evaluator.compute_confusion_matrix(evaluator.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try setting a constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 0.00701754385965 corresponding test error: 0.0\n",
      "params for lowest train error: {'api_probability': 0.8, 'api_count': 10}\n",
      "minimal train error: 0.0101351351351 corresponding test error: 0.0133333333333\n",
      "params for lowest train error: {'api_probability': 0.9, 'api_count': 1}\n",
      "minimal train error: 0.00664451827243 corresponding test error: 0.0384615384615\n",
      "params for lowest train error: {'api_probability': 0.8, 'api_count': 1}\n",
      "minimal train error: 0.00355871886121 corresponding test error: 0.0\n",
      "params for lowest train error: {'api_probability': 0.9, 'api_count': 10}\n",
      "minimal train error: 0.0100334448161 corresponding test error: 0.0142857142857\n",
      "params for lowest train error: {'api_probability': 0.7, 'api_count': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.013216117216117217"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we tune parameters such that 'error_func' is minimised on the training sets \n",
    "# but under the constraint that 'constraint_func' is less than 'constraint_val' on test set\n",
    "evaluator.compute_cv_score(n_splits=5, param_grid=grid, error_func=evaluator.compute_error_without_unknown,\n",
    "                          constraint_func=evaluator.compute_error_with_unknown, constraint_val=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `gender_api`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'all'\n",
    "service_name = GenderAPIEvaluator\n",
    "evaluator = service_name(data_source)\n",
    "\n",
    "evaluator.load_data(evaluated=True)\n",
    "evaluator.preprocess_data_for_parameter_tuning()\n",
    "evaluator.remove_rows_with_unknown_gender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('api_accuracy', 'api_samples')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.tuning_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api_accuracy</th>\n",
       "      <th>api_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5790.000000</td>\n",
       "      <td>5790.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>91.385320</td>\n",
       "      <td>40243.978066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.721861</td>\n",
       "      <td>66650.027682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>987.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>11153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>51412.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>433182.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       api_accuracy    api_samples\n",
       "count   5790.000000    5790.000000\n",
       "mean      91.385320   40243.978066\n",
       "std       18.721861   66650.027682\n",
       "min        0.000000       0.000000\n",
       "25%       95.000000     987.000000\n",
       "50%       98.000000   11153.000000\n",
       "75%       99.000000   51412.000000\n",
       "max      100.000000  433182.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.test_data[list(evaluator.tuning_params)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = evaluator.build_parameter_grid([50, 60, 70, 80, 90, 95], [10000, 20000, 30000, 40000, 50000, 60000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 0.00460405156538 corresponding test error: 0.00684931506849\n",
      "params for lowest train error: {'api_samples': 50000, 'api_accuracy': 95}\n",
      "minimal train error: 0.00522951772225 corresponding test error: 0.00660792951542\n",
      "params for lowest train error: {'api_samples': 20000, 'api_accuracy': 95}\n",
      "minimal train error: 0.00542005420054 corresponding test error: 0.00369003690037\n",
      "params for lowest train error: {'api_samples': 50000, 'api_accuracy': 95}\n",
      "minimal train error: 0.00441014332966 corresponding test error: 0.010152284264\n",
      "params for lowest train error: {'api_samples': 60000, 'api_accuracy': 95}\n",
      "minimal train error: 0.00546946216955 corresponding test error: 0.00355871886121\n",
      "params for lowest train error: {'api_samples': 50000, 'api_accuracy': 95}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0061716569218900012"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(5, grid, evaluator.compute_error_without_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 1.00476190476 corresponding test error: 0.944630872483\n",
      "params for lowest train error: {'api_samples': 10000, 'api_accuracy': 50}\n",
      "minimal train error: 1.00954446855 corresponding test error: 0.926788685524\n",
      "params for lowest train error: {'api_samples': 10000, 'api_accuracy': 50}\n",
      "minimal train error: 0.96855078623 corresponding test error: 1.09403254973\n",
      "params for lowest train error: {'api_samples': 10000, 'api_accuracy': 50}\n",
      "minimal train error: 0.981180496151 corresponding test error: 1.03873239437\n",
      "params for lowest train error: {'api_samples': 10000, 'api_accuracy': 50}\n",
      "minimal train error: 0.998705780846 corresponding test error: 0.96768707483\n",
      "params for lowest train error: {'api_samples': 10000, 'api_accuracy': 50}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99437431538644583"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(5, grid, evaluator.compute_error_with_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal train error: 1.00889328063 corresponding test error: 1.01119402985\n",
      "params for lowest train error: {'api_samples': 20000, 'api_accuracy': 95}\n",
      "minimal train error: 1.00872093023 corresponding test error: 1.01209677419\n",
      "params for lowest train error: {'api_samples': 20000, 'api_accuracy': 95}\n",
      "minimal train error: 1.01046337818 corresponding test error: 1.00943396226\n",
      "params for lowest train error: {'api_samples': 10000, 'api_accuracy': 95}\n",
      "minimal train error: 1.00863723608 corresponding test error: 1.01260504202\n",
      "params for lowest train error: {'api_samples': 20000, 'api_accuracy': 95}\n",
      "minimal train error: 1.0099009901 corresponding test error: 1.00740740741\n",
      "params for lowest train error: {'api_samples': 20000, 'api_accuracy': 95}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.010547443146532"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_cv_score(5, grid, evaluator.compute_inverse_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
